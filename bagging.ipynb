{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Trees: Ensemble Methods - Bagging\n",
    "\n",
    "Bagging: Training a bunch of individual models in a parallel way. Each model is trained by a random subset of the data. (Summary!)\n",
    "\n",
    "BAGGing stands for Bootstrapping(sampling with replacement) and AGGregating (Averaging predictions).\n",
    "\n",
    "### <strong> Random Forest </strong>\n",
    "\n",
    "With Random Forest in addition to taking the random subset of data, it also takes the random selection of features rather than using all features to grow trees. When you have many random trees. It’s called Random Forest.\n",
    "\n",
    "With Random Forest, our goal is to reduce the variance of a decision Tree. We end up with an ensemble of different models. Average of all the predictions from different trees are used which is more robust than a single decision tree.\n",
    "\n",
    "- forests = high variance, low bias base learners\n",
    "- Bagging to decrease the model’s variance\n",
    "\n",
    "<img src=\"./images/boostrap_aggregating.png\" width=\"500\" height=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong> Extremely Randomized Trees </strong>\n",
    "\n",
    "Extremely Randomized Trees, abbreviated as ExtraTrees in Sklearn, adds one more step of randomization to the random forest algorithm. \n",
    "\n",
    "Random forests will \n",
    "\n",
    "1. compute the optimal split to make for each feature within the randomly selected subset, and it will then choose the best feature to split on. \n",
    "2. builds multiple trees with bootstrap = True (by default), which means it samples replacement.\n",
    "\n",
    "ExtraTrees on the other hand(compared to Random Forests) will instead choose a random split to make for each feature within that random subset, and it will subsequently choose the best feature to split on by comparing those randomly chosen splits. (nodes are split on random splits, not best splits.)\n",
    "\n",
    "Like random forest, the Extra Trees algorithm will randomly sample the features at each split point of a decision tree. Unlike random forest, which uses a greedy algorithm to select an optimal split point, the Extra Trees algorithm selects a split point at random.\n",
    "\n",
    "In terms of computational cost, and therefore execution time, the Extra Trees algorithm is faster. This algorithm saves time because the whole procedure is the same, but it randomly chooses the split point and does not calculate the optimal one.\n",
    "\n",
    "Extremely randomized trees are much more computationally efficient than random forests, and their performance is almost always comparable. In some cases, they may even perform better!\n",
    "\n",
    "![Bagging](./images/rf_extra.png)\n",
    "\n",
    "Link to Paper: https://link.springer.com/content/pdf/10.1007/s10994-006-6226-1.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as numpy\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load dataset\n",
    "\n",
    "X,y = load_iris(return_X_y=True)\n",
    "\n",
    "#train,test split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42)\n",
    "\n",
    "#random forest with gini\n",
    "rf = RandomForestClassifier(criterion='gini',n_estimators=150,max_depth=4,n_jobs=-1)\n",
    "\n",
    "rf.fit(X_train,y_train)  #fit on the data\n",
    "\n",
    "rf_predict = rf.predict(X_test)\n",
    "\n",
    "f1_score(y_test, rf_predict, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random forest with gini\n",
    "rf = RandomForestClassifier(criterion='entropy',n_estimators=200,max_depth=4,n_jobs=-1)\n",
    "\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "rf_predict = rf.predict(X_test)\n",
    "\n",
    "f1_score(y_test, rf_predict, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Using the data in scout_data, build a model to predict a product tier(Classification) and a model to predict the number of detail views.(Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78321, 12)\n",
      "(78297, 12)\n",
      "   article_id product_tier      make_name  price  first_zip_digit  \\\n",
      "0   350625839        Basic     Mitsubishi  16750                5   \n",
      "1   354412280        Basic  Mercedes-Benz  35950                4   \n",
      "2   349572992        Basic  Mercedes-Benz  11950                3   \n",
      "3   350266763        Basic           Ford   1750                6   \n",
      "4   355688985        Basic  Mercedes-Benz  26500                3   \n",
      "\n",
      "   first_registration_year created_date deleted_date  search_views  \\\n",
      "0                     2013     24.07.18     24.08.18        3091.0   \n",
      "1                     2015     16.08.18     07.10.18        3283.0   \n",
      "2                     1998     16.07.18     05.09.18        3247.0   \n",
      "3                     2003     20.07.18     29.10.18        1856.0   \n",
      "4                     2014     28.08.18     08.09.18         490.0   \n",
      "\n",
      "   detail_views  stock_days                   ctr  \n",
      "0         123.0          30   0.03780329990294403  \n",
      "1         223.0          52   0.06792567773378008  \n",
      "2         265.0          51    0.0816137973514013  \n",
      "3          26.0         101  0.014008620689655173  \n",
      "4          20.0          12   0.04081632653061224  \n",
      "         article_id          price  first_zip_digit  first_registration_year  \\\n",
      "count  7.829700e+04   78297.000000     78297.000000             78297.000000   \n",
      "mean   3.574864e+08   15069.670358         4.631876              2011.090336   \n",
      "std    5.076809e+06   16375.598837         2.354368                 6.538638   \n",
      "min    3.472324e+08      50.000000         1.000000              1924.000000   \n",
      "25%    3.536387e+08    5750.000000         3.000000              2008.000000   \n",
      "50%    3.585479e+08   10909.000000         5.000000              2013.000000   \n",
      "75%    3.614817e+08   18890.000000         7.000000              2015.000000   \n",
      "max    3.647040e+08  249888.000000         9.000000              2106.000000   \n",
      "\n",
      "       search_views  detail_views    stock_days  \n",
      "count   78297.00000  78297.000000  78297.000000  \n",
      "mean     2297.91333     93.486583     35.995070  \n",
      "std      6339.52668    228.042547     32.213083  \n",
      "min         1.00000      0.000000     -3.000000  \n",
      "25%       368.00000     13.000000     10.000000  \n",
      "50%       920.00000     36.000000     25.000000  \n",
      "75%      2234.00000     94.000000     55.000000  \n",
      "max    608754.00000  13926.000000    127.000000  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/scout_data/Case_Study_Data.csv\",sep=';')\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "data = data.dropna()\n",
    "\n",
    "#print(data.dropna().shape)\n",
    "print(data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78297, 12)\n",
      "         article_id          price  first_zip_digit  first_registration_year  \\\n",
      "count  7.829700e+04   78297.000000     78297.000000             78297.000000   \n",
      "mean   3.574864e+08   15069.670358         4.631876              2011.090336   \n",
      "std    5.076809e+06   16375.598837         2.354368                 6.538638   \n",
      "min    3.472324e+08      50.000000         1.000000              1924.000000   \n",
      "25%    3.536387e+08    5750.000000         3.000000              2008.000000   \n",
      "50%    3.585479e+08   10909.000000         5.000000              2013.000000   \n",
      "75%    3.614817e+08   18890.000000         7.000000              2015.000000   \n",
      "max    3.647040e+08  249888.000000         9.000000              2106.000000   \n",
      "\n",
      "       search_views  detail_views    stock_days  \n",
      "count   78297.00000  78297.000000  78297.000000  \n",
      "mean     2297.91333     93.486583     35.995070  \n",
      "std      6339.52668    228.042547     32.213083  \n",
      "min         1.00000      0.000000     -3.000000  \n",
      "25%       368.00000     13.000000     10.000000  \n",
      "50%       920.00000     36.000000     25.000000  \n",
      "75%      2234.00000     94.000000     55.000000  \n",
      "max    608754.00000  13926.000000    127.000000  \n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Basic' 'Premium' 'Plus']\n"
     ]
    }
   ],
   "source": [
    "print(data['product_tier'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First model: Build a classifier for the \"product tier\" category. \n",
    " - at first: not worrying too much about werid data. ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78297, 11) \n",
      " (78297,)\n"
     ]
    }
   ],
   "source": [
    "#load dataset\n",
    "X,y = data.drop(['product_tier'], axis=1), data['product_tier']\n",
    "\n",
    "print(X.shape, '\\n', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, right: we'll need to encode the categorical data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   article_id      make_name  price  first_zip_digit  first_registration_year  \\\n",
      "0   350625839     Mitsubishi  16750                5                     2013   \n",
      "1   354412280  Mercedes-Benz  35950                4                     2015   \n",
      "2   349572992  Mercedes-Benz  11950                3                     1998   \n",
      "3   350266763           Ford   1750                6                     2003   \n",
      "4   355688985  Mercedes-Benz  26500                3                     2014   \n",
      "\n",
      "  created_date deleted_date  search_views  detail_views  stock_days  \\\n",
      "0     24.07.18     24.08.18        3091.0         123.0          30   \n",
      "1     16.08.18     07.10.18        3283.0         223.0          52   \n",
      "2     16.07.18     05.09.18        3247.0         265.0          51   \n",
      "3     20.07.18     29.10.18        1856.0          26.0         101   \n",
      "4     28.08.18     08.09.18         490.0          20.0          12   \n",
      "\n",
      "                    ctr  \n",
      "0   0.03780329990294403  \n",
      "1   0.06792567773378008  \n",
      "2    0.0816137973514013  \n",
      "3  0.014008620689655173  \n",
      "4   0.04081632653061224   \n",
      "\n",
      "article_id                   int64\n",
      "make_name                   object\n",
      "price                        int64\n",
      "first_zip_digit              int64\n",
      "first_registration_year      int64\n",
      "created_date                object\n",
      "deleted_date                object\n",
      "search_views               float64\n",
      "detail_views               float64\n",
      "stock_days                   int64\n",
      "ctr                         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X.head(), '\\n')\n",
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK ... I'll just drop created_date and deleted_date. But what's ctr?\n",
    "\n",
    "\"ctr;Click through rate calculated as the quotient of detail_views over search_views\"\n",
    "\n",
    "Why is this not a float? Let's try to make it one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['article_id', 'make_name', 'price', 'first_zip_digit',\n",
      "       'first_registration_year', 'created_date', 'deleted_date',\n",
      "       'search_views', 'detail_views', 'stock_days', 'ctr'],\n",
      "      dtype='object')\n",
      "(78297, 9)\n"
     ]
    }
   ],
   "source": [
    "print(X.columns)\n",
    "\n",
    "X = X.drop(['created_date', 'deleted_date'], axis=1)\n",
    "# Merke: kann man nur einmal machen. ;-)\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     78297\n",
       "unique    47246\n",
       "top         0.0\n",
       "freq       1244\n",
       "Name: ctr, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X['ctr'] = X['ctr'].astype('float64')\n",
    "X['ctr'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, diese Column macht seltsame Sachen. For now: ignorieren!\n",
    "\n",
    "Todo: einen besseren Umgang finden!? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop this thing: \n",
    "X = X.drop(['ctr'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next: Encode!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       article_id      make_name  price  first_zip_digit  \\\n",
      "0       350625839     Mitsubishi  16750                5   \n",
      "1       354412280  Mercedes-Benz  35950                4   \n",
      "2       349572992  Mercedes-Benz  11950                3   \n",
      "3       350266763           Ford   1750                6   \n",
      "4       355688985  Mercedes-Benz  26500                3   \n",
      "...           ...            ...    ...              ...   \n",
      "78316   348704581          Lexus  15740                8   \n",
      "78317   359231940        Hyundai   2950                6   \n",
      "78318   362425932     Volkswagen   7850                8   \n",
      "78319   357164227         Toyota  13945                5   \n",
      "78320   353639932     Volkswagen  38800                7   \n",
      "\n",
      "       first_registration_year  search_views  detail_views  stock_days  \n",
      "0                         2013        3091.0         123.0          30  \n",
      "1                         2015        3283.0         223.0          52  \n",
      "2                         1998        3247.0         265.0          51  \n",
      "3                         2003        1856.0          26.0         101  \n",
      "4                         2014         490.0          20.0          12  \n",
      "...                        ...           ...           ...         ...  \n",
      "78316                     2014        6895.0         230.0          99  \n",
      "78317                     2006        1175.0          16.0          25  \n",
      "78318                     2014         448.0          21.0          16  \n",
      "78319                     2011        1617.0          29.0          28  \n",
      "78320                     2018          55.0           2.0           1  \n",
      "\n",
      "[78297 rows x 8 columns]\n",
      "       article_id  make_name_1  make_name_2  make_name_3  make_name_4  \\\n",
      "0       350625839            1            0            0            0   \n",
      "1       354412280            0            1            0            0   \n",
      "2       349572992            0            1            0            0   \n",
      "3       350266763            0            0            1            0   \n",
      "4       355688985            0            1            0            0   \n",
      "...           ...          ...          ...          ...          ...   \n",
      "78316   348704581            0            0            0            0   \n",
      "78317   359231940            0            0            0            0   \n",
      "78318   362425932            0            0            0            1   \n",
      "78319   357164227            0            0            0            0   \n",
      "78320   353639932            0            0            0            1   \n",
      "\n",
      "       make_name_5  make_name_6  make_name_7  make_name_8  make_name_9  ...  \\\n",
      "0                0            0            0            0            0  ...   \n",
      "1                0            0            0            0            0  ...   \n",
      "2                0            0            0            0            0  ...   \n",
      "3                0            0            0            0            0  ...   \n",
      "4                0            0            0            0            0  ...   \n",
      "...            ...          ...          ...          ...          ...  ...   \n",
      "78316            0            0            0            0            0  ...   \n",
      "78317            0            0            0            0            0  ...   \n",
      "78318            0            0            0            0            0  ...   \n",
      "78319            0            0            0            0            0  ...   \n",
      "78320            0            0            0            0            0  ...   \n",
      "\n",
      "       make_name_88  make_name_89  make_name_90  make_name_91  price  \\\n",
      "0                 0             0             0             0  16750   \n",
      "1                 0             0             0             0  35950   \n",
      "2                 0             0             0             0  11950   \n",
      "3                 0             0             0             0   1750   \n",
      "4                 0             0             0             0  26500   \n",
      "...             ...           ...           ...           ...    ...   \n",
      "78316             0             0             0             0  15740   \n",
      "78317             0             0             0             0   2950   \n",
      "78318             0             0             0             0   7850   \n",
      "78319             0             0             0             0  13945   \n",
      "78320             0             0             0             0  38800   \n",
      "\n",
      "       first_zip_digit  first_registration_year  search_views  detail_views  \\\n",
      "0                    5                     2013        3091.0         123.0   \n",
      "1                    4                     2015        3283.0         223.0   \n",
      "2                    3                     1998        3247.0         265.0   \n",
      "3                    6                     2003        1856.0          26.0   \n",
      "4                    3                     2014         490.0          20.0   \n",
      "...                ...                      ...           ...           ...   \n",
      "78316                8                     2014        6895.0         230.0   \n",
      "78317                6                     2006        1175.0          16.0   \n",
      "78318                8                     2014         448.0          21.0   \n",
      "78319                5                     2011        1617.0          29.0   \n",
      "78320                7                     2018          55.0           2.0   \n",
      "\n",
      "       stock_days  \n",
      "0              30  \n",
      "1              52  \n",
      "2              51  \n",
      "3             101  \n",
      "4              12  \n",
      "...           ...  \n",
      "78316          99  \n",
      "78317          25  \n",
      "78318          16  \n",
      "78319          28  \n",
      "78320           1  \n",
      "\n",
      "[78297 rows x 98 columns]\n"
     ]
    }
   ],
   "source": [
    "#one hot encoding for make_name column\n",
    "import category_encoders as ce\n",
    "\n",
    "# create an object of the OneHotEncoder\n",
    "ce_one = ce.OneHotEncoder(cols=['make_name'])\n",
    "\n",
    "print(X)\n",
    "\n",
    "Xone = ce_one.fit_transform(X)\n",
    "# Was passiert hier eigentlich?\n",
    "\n",
    "print(Xone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, shit. Warum habe ich 91 make names? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mitsubishi', 'Mercedes-Benz', 'Ford', 'Volkswagen', 'Fiat',\n",
       "       'Renault', 'Mazda', 'Peugeot', 'Opel', 'Toyota', 'Jaguar', 'Volvo',\n",
       "       'Dacia', 'MINI', 'Porsche', 'Nissan', 'BMW', 'Land Rover', 'Audi',\n",
       "       'Citroen', 'Hyundai', 'Suzuki', 'Alfa Romeo', 'Chevrolet',\n",
       "       'Daewoo', 'Kia', 'Maserati', 'Skoda', 'Caravans-Wohnm', 'SEAT',\n",
       "       'Honda', 'Daihatsu', 'Chrysler', 'smart', 'Saab', 'Jeep',\n",
       "       'Others ', 'Lexus', 'Aixam', 'Ligier', 'Lancia', 'Oldtimer',\n",
       "       'Chatenet', 'Subaru', 'Triumph', 'Ferrari', 'Rolls-Royce', 'Dodge',\n",
       "       'MG', 'Cadillac', 'DS Automobiles', 'Iveco', 'Bentley',\n",
       "       'SsangYong', 'Tesla', 'Trucks-Lkw', 'TVR', 'Aston Martin',\n",
       "       'Abarth', 'HUMMER', 'Lincoln', 'Isuzu', 'Microcar', 'Buick', 'AC',\n",
       "       'Alpina', 'Corvette', 'McLaren', 'Rover', 'Austin', 'De Tomaso',\n",
       "       'FISKER', 'Infiniti', 'Lotus', 'Morgan', 'GMC', 'Oldsmobile',\n",
       "       'Donkervoort', 'Alpine', 'Daimler', 'Lamborghini', 'Grecav',\n",
       "       'Casalini', 'Pontiac', 'MAN', 'Piaggio', 'Amphicar', 'Tata',\n",
       "       'DFSK', 'Kawasaki', 'KTM'], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['make_name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, offensichtlich habe ich da vorhin was falsch gemacht. :-) \n",
    "\n",
    "Ah, oder hatte ich nur nach dem Target geschaut? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       product_tier_1  product_tier_2  product_tier_3\n",
      "0                   1               0               0\n",
      "1                   1               0               0\n",
      "2                   1               0               0\n",
      "3                   1               0               0\n",
      "4                   1               0               0\n",
      "...               ...             ...             ...\n",
      "78316               1               0               0\n",
      "78317               1               0               0\n",
      "78318               1               0               0\n",
      "78319               1               0               0\n",
      "78320               1               0               0\n",
      "\n",
      "[78297 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#one hot encoding for make_name column\n",
    "import category_encoders as ce\n",
    "\n",
    "# create an object of the OneHotEncoder\n",
    "ce_one = ce.OneHotEncoder(cols=['product_tier'])\n",
    "\n",
    "\n",
    "y = ce_one.fit_transform(y)\n",
    "# Was passiert hier eigentlich?\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Basic\n",
      "1        Basic\n",
      "2        Basic\n",
      "3        Basic\n",
      "4        Basic\n",
      "         ...  \n",
      "78316    Basic\n",
      "78317    Basic\n",
      "78318    Basic\n",
      "78319    Basic\n",
      "78320    Basic\n",
      "Name: product_tier, Length: 78297, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Target encoding\n",
    "ce_te = ce.TargetEncoder(cols=['make_name'])\n",
    "\n",
    "#column to perform encoding\n",
    "Xmake = X['make_name']\n",
    "#y = data['color']\n",
    "print(y)\n",
    "#create an object of the Targetencoder\n",
    "#ce_te.fit(Xmake,y)\n",
    "\n",
    "TODO: Hier war ich gerade ...\n",
    "\n",
    "#ce_te.transform(Xmake).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Skoda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_60005/1365332561.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#initialize the decisiontreeclassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#dtc = tree.DecisionTreeClassifier(max_depth=5,random_state=42,criterion='gini')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#fit and return f1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlfund/lib/python3.12/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1469\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1470\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mlfund/lib/python3.12/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \"\"\"\n\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m         super()._fit(\n\u001b[0m\u001b[1;32m   1010\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlfund/lib/python3.12/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    248\u001b[0m             check_X_params = dict(\n\u001b[1;32m    249\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    253\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlfund/lib/python3.12/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    641\u001b[0m                 \u001b[0;31m# :(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m                 \u001b[0mcheck_X_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_X_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                     \u001b[0mcheck_X_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlfund/lib/python3.12/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1009\u001b[0m                         \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m                 raise ValueError(\n\u001b[1;32m   1015\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m                 \u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlfund/lib/python3.12/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlfund/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   2149\u001b[0m     def __array__(\n\u001b[1;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m     \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m         if (\n\u001b[1;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Skoda'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "#train_test_split\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "#initialize the decisiontreeclassifier\n",
    "#dtc = tree.DecisionTreeClassifier(max_depth=5,random_state=42,criterion='gini')\n",
    "\n",
    "#fit and return f1_score\n",
    "dtc.fit(X_train,y_train)\n",
    "f1_score(y_test,dtc.predict(X_test),average=None)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
